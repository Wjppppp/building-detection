{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "265907f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May 15 08:31:53 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.104      Driver Version: 528.78       CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   51C    P8    12W /  93W |    197MiB /  6144MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2021 NVIDIA Corporation\n",
      "Built on Sun_Feb_14_21:12:58_PST_2021\n",
      "Cuda compilation tools, release 11.2, V11.2.152\n",
      "Build cuda_11.2.r11.2/compiler.29618528_0\n",
      "tensorflow version:  2.6.2\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# check cuda, cudnn, tensorflow\n",
    "\n",
    "nvidia-smi\n",
    "nvcc -V\n",
    "python -c \"import tensorflow as tf;print('tensorflow version: ',tf.__version__)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9360162",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7c124f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d27e8135",
   "metadata": {},
   "source": [
    "#### Make sure you are working under `training_demo/`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d183105b",
   "metadata": {},
   "source": [
    "## Preparing the dataset\n",
    "\n",
    "Copy `train.record` and `valid.record` to `training_demo/annotations/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157f0e71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2683f7d4",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfb209fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-03 10:50:53.359553: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-03 10:50:53.366796: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-03 10:50:53.367093: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-03 10:50:53.367662: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-03 10:50:53.369370: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-03 10:50:53.369667: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-03 10:50:53.369927: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-03 10:50:53.923299: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-03 10:50:53.923671: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-03 10:50:53.923693: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1594] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-05-03 10:50:53.923952: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-03 10:50:53.924025: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3443 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "I0503 10:50:54.085503 140603801323328 mirrored_strategy.py:369] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "INFO:tensorflow:Maybe overwriting train_steps: None\n",
      "I0503 10:50:54.091881 140603801323328 config_util.py:552] Maybe overwriting train_steps: None\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I0503 10:50:54.092024 140603801323328 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "W0503 10:50:54.163884 140603801323328 deprecation.py:345] From /usr/local/lib/python3.6/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "INFO:tensorflow:Reading unweighted datasets: ['annotations/train.record']\n",
      "I0503 10:50:54.182559 140603801323328 dataset_builder.py:162] Reading unweighted datasets: ['annotations/train.record']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['annotations/train.record']\n",
      "I0503 10:50:54.183486 140603801323328 dataset_builder.py:79] Reading record datasets for input file: ['annotations/train.record']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I0503 10:50:54.183696 140603801323328 dataset_builder.py:80] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W0503 10:50:54.183798 140603801323328 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
      "W0503 10:50:54.187024 140603801323328 deprecation.py:345] From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0503 10:50:54.213708 140603801323328 deprecation.py:345] From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W0503 10:51:00.035594 140603801323328 deprecation.py:345] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:206: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "W0503 10:51:02.520486 140603801323328 deprecation.py:345] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:206: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0503 10:51:03.874452 140603801323328 deprecation.py:345] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-03 10:51:05.593490: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "/usr/local/lib/python3.6/dist-packages/keras/backend.py:401: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
      "I0503 10:51:10.465590 140593732773632 api.py:446] feature_map_spatial_dims: [(32, 32), (16, 16), (8, 8), (4, 4), (2, 2)]\n",
      "I0503 10:51:18.153299 140593732773632 api.py:446] feature_map_spatial_dims: [(32, 32), (16, 16), (8, 8), (4, 4), (2, 2)]\n",
      "2023-05-03 10:51:22.800698: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8100\n",
      "2023-05-03 10:51:24.805587: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0503 10:51:27.372099 140603801323328 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0503 10:51:27.373319 140603801323328 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0503 10:51:27.376110 140603801323328 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0503 10:51:27.377347 140603801323328 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0503 10:51:27.379720 140603801323328 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0503 10:51:27.380896 140603801323328 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0503 10:51:27.384511 140603801323328 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0503 10:51:27.385906 140603801323328 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0503 10:51:27.388164 140603801323328 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0503 10:51:27.388981 140603801323328 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py:617: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "W0503 10:51:28.458383 140593875384064 deprecation.py:548] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py:617: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "I0503 10:51:29.037504 140593875384064 api.py:446] feature_map_spatial_dims: [(32, 32), (16, 16), (8, 8), (4, 4), (2, 2)]\n",
      "I0503 10:51:33.120661 140593875384064 api.py:446] feature_map_spatial_dims: [(32, 32), (16, 16), (8, 8), (4, 4), (2, 2)]\n",
      "I0503 10:51:36.827383 140593875384064 api.py:446] feature_map_spatial_dims: [(32, 32), (16, 16), (8, 8), (4, 4), (2, 2)]\n",
      "I0503 10:51:42.940653 140593875384064 api.py:446] feature_map_spatial_dims: [(32, 32), (16, 16), (8, 8), (4, 4), (2, 2)]\n",
      "2023-05-03 10:51:53.918831: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.09GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2023-05-03 10:51:53.918897: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.09GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2023-05-03 10:51:53.939024: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2023-05-03 10:51:53.939087: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2023-05-03 10:51:54.472644: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2023-05-03 10:51:54.472722: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2023-05-03 10:51:54.481748: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.30GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2023-05-03 10:51:54.481810: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.30GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2023-05-03 10:51:54.558747: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2023-05-03 10:51:54.558818: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Step 100 per-step time 0.490s\n",
      "I0503 10:52:17.144510 140603801323328 model_lib_v2.py:707] Step 100 per-step time 0.490s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.9208105,\n",
      " 'Loss/localization_loss': 1.2354395,\n",
      " 'Loss/regularization_loss': 3.0064318,\n",
      " 'Loss/total_loss': 5.1626816,\n",
      " 'learning_rate': 0.014666351}\n",
      "I0503 10:52:17.144782 140603801323328 model_lib_v2.py:708] {'Loss/classification_loss': 0.9208105,\n",
      " 'Loss/localization_loss': 1.2354395,\n",
      " 'Loss/regularization_loss': 3.0064318,\n",
      " 'Loss/total_loss': 5.1626816,\n",
      " 'learning_rate': 0.014666351}\n",
      "INFO:tensorflow:Step 200 per-step time 0.230s\n",
      "I0503 10:52:40.188181 140603801323328 model_lib_v2.py:707] Step 200 per-step time 0.230s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.6854787,\n",
      " 'Loss/localization_loss': 0.9672884,\n",
      " 'Loss/regularization_loss': 2.972033,\n",
      " 'Loss/total_loss': 4.6248,\n",
      " 'learning_rate': 0.0159997}\n",
      "I0503 10:52:40.188464 140603801323328 model_lib_v2.py:708] {'Loss/classification_loss': 0.6854787,\n",
      " 'Loss/localization_loss': 0.9672884,\n",
      " 'Loss/regularization_loss': 2.972033,\n",
      " 'Loss/total_loss': 4.6248,\n",
      " 'learning_rate': 0.0159997}\n",
      "INFO:tensorflow:Step 300 per-step time 0.224s\n",
      "I0503 10:53:02.541052 140603801323328 model_lib_v2.py:707] Step 300 per-step time 0.224s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.72231686,\n",
      " 'Loss/localization_loss': 0.97179466,\n",
      " 'Loss/regularization_loss': 2.934294,\n",
      " 'Loss/total_loss': 4.6284056,\n",
      " 'learning_rate': 0.01733305}\n",
      "I0503 10:53:02.541301 140603801323328 model_lib_v2.py:708] {'Loss/classification_loss': 0.72231686,\n",
      " 'Loss/localization_loss': 0.97179466,\n",
      " 'Loss/regularization_loss': 2.934294,\n",
      " 'Loss/total_loss': 4.6284056,\n",
      " 'learning_rate': 0.01733305}\n",
      "INFO:tensorflow:Step 400 per-step time 0.225s\n",
      "I0503 10:53:25.091393 140603801323328 model_lib_v2.py:707] Step 400 per-step time 0.225s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.5004847,\n",
      " 'Loss/localization_loss': 0.87331843,\n",
      " 'Loss/regularization_loss': 2.893774,\n",
      " 'Loss/total_loss': 4.267577,\n",
      " 'learning_rate': 0.0186664}\n",
      "I0503 10:53:25.091986 140603801323328 model_lib_v2.py:708] {'Loss/classification_loss': 0.5004847,\n",
      " 'Loss/localization_loss': 0.87331843,\n",
      " 'Loss/regularization_loss': 2.893774,\n",
      " 'Loss/total_loss': 4.267577,\n",
      " 'learning_rate': 0.0186664}\n",
      "INFO:tensorflow:Step 500 per-step time 0.229s\n",
      "I0503 10:53:47.951658 140603801323328 model_lib_v2.py:707] Step 500 per-step time 0.229s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.5695968,\n",
      " 'Loss/localization_loss': 0.741986,\n",
      " 'Loss/regularization_loss': 2.850803,\n",
      " 'Loss/total_loss': 4.162386,\n",
      " 'learning_rate': 0.01999975}\n",
      "I0503 10:53:47.951877 140603801323328 model_lib_v2.py:708] {'Loss/classification_loss': 0.5695968,\n",
      " 'Loss/localization_loss': 0.741986,\n",
      " 'Loss/regularization_loss': 2.850803,\n",
      " 'Loss/total_loss': 4.162386,\n",
      " 'learning_rate': 0.01999975}\n",
      "INFO:tensorflow:Step 600 per-step time 0.225s\n",
      "I0503 10:54:10.410960 140603801323328 model_lib_v2.py:707] Step 600 per-step time 0.225s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.48688993,\n",
      " 'Loss/localization_loss': 0.6930868,\n",
      " 'Loss/regularization_loss': 2.8060803,\n",
      " 'Loss/total_loss': 3.986057,\n",
      " 'learning_rate': 0.0213331}\n",
      "I0503 10:54:10.411181 140603801323328 model_lib_v2.py:708] {'Loss/classification_loss': 0.48688993,\n",
      " 'Loss/localization_loss': 0.6930868,\n",
      " 'Loss/regularization_loss': 2.8060803,\n",
      " 'Loss/total_loss': 3.986057,\n",
      " 'learning_rate': 0.0213331}\n",
      "INFO:tensorflow:Step 700 per-step time 0.225s\n",
      "I0503 10:54:32.871009 140603801323328 model_lib_v2.py:707] Step 700 per-step time 0.225s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.4642436,\n",
      " 'Loss/localization_loss': 0.60872865,\n",
      " 'Loss/regularization_loss': 2.7593417,\n",
      " 'Loss/total_loss': 3.832314,\n",
      " 'learning_rate': 0.02266645}\n",
      "I0503 10:54:32.871227 140603801323328 model_lib_v2.py:708] {'Loss/classification_loss': 0.4642436,\n",
      " 'Loss/localization_loss': 0.60872865,\n",
      " 'Loss/regularization_loss': 2.7593417,\n",
      " 'Loss/total_loss': 3.832314,\n",
      " 'learning_rate': 0.02266645}\n",
      "INFO:tensorflow:Step 800 per-step time 0.223s\n",
      "I0503 10:54:55.205072 140603801323328 model_lib_v2.py:707] Step 800 per-step time 0.223s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.4471686,\n",
      " 'Loss/localization_loss': 0.6969306,\n",
      " 'Loss/regularization_loss': 2.710696,\n",
      " 'Loss/total_loss': 3.8547952,\n",
      " 'learning_rate': 0.023999799}\n",
      "I0503 10:54:55.205331 140603801323328 model_lib_v2.py:708] {'Loss/classification_loss': 0.4471686,\n",
      " 'Loss/localization_loss': 0.6969306,\n",
      " 'Loss/regularization_loss': 2.710696,\n",
      " 'Loss/total_loss': 3.8547952,\n",
      " 'learning_rate': 0.023999799}\n",
      "INFO:tensorflow:Step 900 per-step time 0.226s\n",
      "I0503 10:55:17.810067 140603801323328 model_lib_v2.py:707] Step 900 per-step time 0.226s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.41927046,\n",
      " 'Loss/localization_loss': 0.40700108,\n",
      " 'Loss/regularization_loss': 2.6603568,\n",
      " 'Loss/total_loss': 3.4866283,\n",
      " 'learning_rate': 0.025333151}\n",
      "I0503 10:55:17.810327 140603801323328 model_lib_v2.py:708] {'Loss/classification_loss': 0.41927046,\n",
      " 'Loss/localization_loss': 0.40700108,\n",
      " 'Loss/regularization_loss': 2.6603568,\n",
      " 'Loss/total_loss': 3.4866283,\n",
      " 'learning_rate': 0.025333151}\n",
      "INFO:tensorflow:Step 1000 per-step time 0.225s\n",
      "I0503 10:55:40.267065 140603801323328 model_lib_v2.py:707] Step 1000 per-step time 0.225s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.40002164,\n",
      " 'Loss/localization_loss': 0.4020795,\n",
      " 'Loss/regularization_loss': 2.6083798,\n",
      " 'Loss/total_loss': 3.410481,\n",
      " 'learning_rate': 0.0266665}\n",
      "I0503 10:55:40.267294 140603801323328 model_lib_v2.py:708] {'Loss/classification_loss': 0.40002164,\n",
      " 'Loss/localization_loss': 0.4020795,\n",
      " 'Loss/regularization_loss': 2.6083798,\n",
      " 'Loss/total_loss': 3.410481,\n",
      " 'learning_rate': 0.0266665}\n",
      "INFO:tensorflow:Step 1100 per-step time 0.330s\n",
      "I0503 10:56:13.264926 140603801323328 model_lib_v2.py:707] Step 1100 per-step time 0.330s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.40257666,\n",
      " 'Loss/localization_loss': 0.71128035,\n",
      " 'Loss/regularization_loss': 2.5545301,\n",
      " 'Loss/total_loss': 3.6683872,\n",
      " 'learning_rate': 0.02799985}\n",
      "I0503 10:56:13.265159 140603801323328 model_lib_v2.py:708] {'Loss/classification_loss': 0.40257666,\n",
      " 'Loss/localization_loss': 0.71128035,\n",
      " 'Loss/regularization_loss': 2.5545301,\n",
      " 'Loss/total_loss': 3.6683872,\n",
      " 'learning_rate': 0.02799985}\n",
      "INFO:tensorflow:Step 1200 per-step time 0.225s\n",
      "I0503 10:56:35.794841 140603801323328 model_lib_v2.py:707] Step 1200 per-step time 0.225s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.42753392,\n",
      " 'Loss/localization_loss': 0.5499163,\n",
      " 'Loss/regularization_loss': 2.500032,\n",
      " 'Loss/total_loss': 3.4774823,\n",
      " 'learning_rate': 0.0293332}\n",
      "I0503 10:56:35.795070 140603801323328 model_lib_v2.py:708] {'Loss/classification_loss': 0.42753392,\n",
      " 'Loss/localization_loss': 0.5499163,\n",
      " 'Loss/regularization_loss': 2.500032,\n",
      " 'Loss/total_loss': 3.4774823,\n",
      " 'learning_rate': 0.0293332}\n",
      "INFO:tensorflow:Step 1300 per-step time 0.236s\n",
      "I0503 10:56:59.366338 140603801323328 model_lib_v2.py:707] Step 1300 per-step time 0.236s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.3787375,\n",
      " 'Loss/localization_loss': 0.4617206,\n",
      " 'Loss/regularization_loss': 2.4435072,\n",
      " 'Loss/total_loss': 3.2839653,\n",
      " 'learning_rate': 0.03066655}\n",
      "I0503 10:56:59.366608 140603801323328 model_lib_v2.py:708] {'Loss/classification_loss': 0.3787375,\n",
      " 'Loss/localization_loss': 0.4617206,\n",
      " 'Loss/regularization_loss': 2.4435072,\n",
      " 'Loss/total_loss': 3.2839653,\n",
      " 'learning_rate': 0.03066655}\n",
      "INFO:tensorflow:Step 1400 per-step time 0.246s\n",
      "I0503 10:57:23.956972 140603801323328 model_lib_v2.py:707] Step 1400 per-step time 0.246s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.4186008,\n",
      " 'Loss/localization_loss': 0.48061046,\n",
      " 'Loss/regularization_loss': 2.3859696,\n",
      " 'Loss/total_loss': 3.285181,\n",
      " 'learning_rate': 0.0319999}\n",
      "I0503 10:57:23.957205 140603801323328 model_lib_v2.py:708] {'Loss/classification_loss': 0.4186008,\n",
      " 'Loss/localization_loss': 0.48061046,\n",
      " 'Loss/regularization_loss': 2.3859696,\n",
      " 'Loss/total_loss': 3.285181,\n",
      " 'learning_rate': 0.0319999}\n",
      "INFO:tensorflow:Step 1500 per-step time 0.247s\n",
      "I0503 10:57:48.606034 140603801323328 model_lib_v2.py:707] Step 1500 per-step time 0.247s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.4153209,\n",
      " 'Loss/localization_loss': 0.3825171,\n",
      " 'Loss/regularization_loss': 2.3274863,\n",
      " 'Loss/total_loss': 3.1253242,\n",
      " 'learning_rate': 0.03333325}\n",
      "I0503 10:57:48.606303 140603801323328 model_lib_v2.py:708] {'Loss/classification_loss': 0.4153209,\n",
      " 'Loss/localization_loss': 0.3825171,\n",
      " 'Loss/regularization_loss': 2.3274863,\n",
      " 'Loss/total_loss': 3.1253242,\n",
      " 'learning_rate': 0.03333325}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Step 1600 per-step time 0.240s\n",
      "I0503 10:58:12.632241 140603801323328 model_lib_v2.py:707] Step 1600 per-step time 0.240s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.38582167,\n",
      " 'Loss/localization_loss': 0.5632247,\n",
      " 'Loss/regularization_loss': 2.2685077,\n",
      " 'Loss/total_loss': 3.217554,\n",
      " 'learning_rate': 0.034666598}\n",
      "I0503 10:58:12.632453 140603801323328 model_lib_v2.py:708] {'Loss/classification_loss': 0.38582167,\n",
      " 'Loss/localization_loss': 0.5632247,\n",
      " 'Loss/regularization_loss': 2.2685077,\n",
      " 'Loss/total_loss': 3.217554,\n",
      " 'learning_rate': 0.034666598}\n",
      "INFO:tensorflow:Step 1700 per-step time 0.229s\n",
      "I0503 10:58:35.524143 140603801323328 model_lib_v2.py:707] Step 1700 per-step time 0.229s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.33996764,\n",
      " 'Loss/localization_loss': 0.29366878,\n",
      " 'Loss/regularization_loss': 2.2087088,\n",
      " 'Loss/total_loss': 2.8423452,\n",
      " 'learning_rate': 0.03599995}\n",
      "I0503 10:58:35.524390 140603801323328 model_lib_v2.py:708] {'Loss/classification_loss': 0.33996764,\n",
      " 'Loss/localization_loss': 0.29366878,\n",
      " 'Loss/regularization_loss': 2.2087088,\n",
      " 'Loss/total_loss': 2.8423452,\n",
      " 'learning_rate': 0.03599995}\n",
      "INFO:tensorflow:Step 1800 per-step time 0.236s\n",
      "I0503 10:58:59.079125 140603801323328 model_lib_v2.py:707] Step 1800 per-step time 0.236s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.437919,\n",
      " 'Loss/localization_loss': 0.3915215,\n",
      " 'Loss/regularization_loss': 2.149247,\n",
      " 'Loss/total_loss': 2.9786873,\n",
      " 'learning_rate': 0.037333302}\n",
      "I0503 10:58:59.079425 140603801323328 model_lib_v2.py:708] {'Loss/classification_loss': 0.437919,\n",
      " 'Loss/localization_loss': 0.3915215,\n",
      " 'Loss/regularization_loss': 2.149247,\n",
      " 'Loss/total_loss': 2.9786873,\n",
      " 'learning_rate': 0.037333302}\n",
      "INFO:tensorflow:Step 1900 per-step time 0.260s\n",
      "I0503 10:59:25.045736 140603801323328 model_lib_v2.py:707] Step 1900 per-step time 0.260s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.37644625,\n",
      " 'Loss/localization_loss': 0.27714452,\n",
      " 'Loss/regularization_loss': 2.0890036,\n",
      " 'Loss/total_loss': 2.7425942,\n",
      " 'learning_rate': 0.03866665}\n",
      "I0503 10:59:25.045964 140603801323328 model_lib_v2.py:708] {'Loss/classification_loss': 0.37644625,\n",
      " 'Loss/localization_loss': 0.27714452,\n",
      " 'Loss/regularization_loss': 2.0890036,\n",
      " 'Loss/total_loss': 2.7425942,\n",
      " 'learning_rate': 0.03866665}\n",
      "INFO:tensorflow:Step 2000 per-step time 0.233s\n",
      "I0503 10:59:48.387683 140603801323328 model_lib_v2.py:707] Step 2000 per-step time 0.233s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.38938686,\n",
      " 'Loss/localization_loss': 0.43007877,\n",
      " 'Loss/regularization_loss': 2.0279882,\n",
      " 'Loss/total_loss': 2.8474538,\n",
      " 'learning_rate': 0.04}\n",
      "I0503 10:59:48.387966 140603801323328 model_lib_v2.py:708] {'Loss/classification_loss': 0.38938686,\n",
      " 'Loss/localization_loss': 0.43007877,\n",
      " 'Loss/regularization_loss': 2.0279882,\n",
      " 'Loss/total_loss': 2.8474538,\n",
      " 'learning_rate': 0.04}\n",
      "INFO:tensorflow:Step 2100 per-step time 0.255s\n",
      "I0503 11:00:13.865076 140603801323328 model_lib_v2.py:707] Step 2100 per-step time 0.255s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.3514969,\n",
      " 'Loss/localization_loss': 0.35917705,\n",
      " 'Loss/regularization_loss': 1.9683414,\n",
      " 'Loss/total_loss': 2.6790152,\n",
      " 'learning_rate': 0.039998136}\n",
      "I0503 11:00:13.865409 140603801323328 model_lib_v2.py:708] {'Loss/classification_loss': 0.3514969,\n",
      " 'Loss/localization_loss': 0.35917705,\n",
      " 'Loss/regularization_loss': 1.9683414,\n",
      " 'Loss/total_loss': 2.6790152,\n",
      " 'learning_rate': 0.039998136}\n",
      "INFO:tensorflow:Step 2200 per-step time 0.277s\n",
      "I0503 11:00:41.582144 140603801323328 model_lib_v2.py:707] Step 2200 per-step time 0.277s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.3860762,\n",
      " 'Loss/localization_loss': 0.3307004,\n",
      " 'Loss/regularization_loss': 1.9098682,\n",
      " 'Loss/total_loss': 2.6266448,\n",
      " 'learning_rate': 0.039992537}\n",
      "I0503 11:00:41.582461 140603801323328 model_lib_v2.py:708] {'Loss/classification_loss': 0.3860762,\n",
      " 'Loss/localization_loss': 0.3307004,\n",
      " 'Loss/regularization_loss': 1.9098682,\n",
      " 'Loss/total_loss': 2.6266448,\n",
      " 'learning_rate': 0.039992537}\n",
      "INFO:tensorflow:Step 2300 per-step time 0.260s\n",
      "I0503 11:01:07.589190 140603801323328 model_lib_v2.py:707] Step 2300 per-step time 0.260s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.38186118,\n",
      " 'Loss/localization_loss': 0.37561288,\n",
      " 'Loss/regularization_loss': 1.8534595,\n",
      " 'Loss/total_loss': 2.6109335,\n",
      " 'learning_rate': 0.03998321}\n",
      "I0503 11:01:07.589437 140603801323328 model_lib_v2.py:708] {'Loss/classification_loss': 0.38186118,\n",
      " 'Loss/localization_loss': 0.37561288,\n",
      " 'Loss/regularization_loss': 1.8534595,\n",
      " 'Loss/total_loss': 2.6109335,\n",
      " 'learning_rate': 0.03998321}\n",
      "INFO:tensorflow:Step 2400 per-step time 0.250s\n",
      "I0503 11:01:32.571391 140603801323328 model_lib_v2.py:707] Step 2400 per-step time 0.250s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.33942926,\n",
      " 'Loss/localization_loss': 0.3863483,\n",
      " 'Loss/regularization_loss': 1.7992249,\n",
      " 'Loss/total_loss': 2.5250025,\n",
      " 'learning_rate': 0.039970152}\n",
      "I0503 11:01:32.571652 140603801323328 model_lib_v2.py:708] {'Loss/classification_loss': 0.33942926,\n",
      " 'Loss/localization_loss': 0.3863483,\n",
      " 'Loss/regularization_loss': 1.7992249,\n",
      " 'Loss/total_loss': 2.5250025,\n",
      " 'learning_rate': 0.039970152}\n",
      "INFO:tensorflow:Step 2500 per-step time 0.253s\n",
      "I0503 11:01:57.826096 140603801323328 model_lib_v2.py:707] Step 2500 per-step time 0.253s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.35021362,\n",
      " 'Loss/localization_loss': 0.29793254,\n",
      " 'Loss/regularization_loss': 1.7456874,\n",
      " 'Loss/total_loss': 2.3938336,\n",
      " 'learning_rate': 0.039953373}\n",
      "I0503 11:01:57.826354 140603801323328 model_lib_v2.py:708] {'Loss/classification_loss': 0.35021362,\n",
      " 'Loss/localization_loss': 0.29793254,\n",
      " 'Loss/regularization_loss': 1.7456874,\n",
      " 'Loss/total_loss': 2.3938336,\n",
      " 'learning_rate': 0.039953373}\n"
     ]
    }
   ],
   "source": [
    "!python model_main_tf2.py --model_dir=models/my_ssd_resnet50_v1_fpn --pipeline_config_path=models/my_ssd_resnet50_v1_fpn/pipeline.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0d44f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbd8379",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3a8d53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-03 11:52:36.362315: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-03 11:52:36.369773: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-03 11:52:36.370925: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
      "W0503 11:52:36.377379 139636483225408 model_lib_v2.py:1090] Forced number of epochs for all eval validations to be 1.\n",
      "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None\n",
      "I0503 11:52:36.377555 139636483225408 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I0503 11:52:36.377625 139636483225408 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
      "I0503 11:52:36.377702 139636483225408 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
      "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
      "W0503 11:52:36.377806 139636483225408 model_lib_v2.py:1110] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
      "2023-05-03 11:52:36.381961: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-03 11:52:36.382964: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-03 11:52:36.383233: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-03 11:52:36.383471: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-03 11:52:36.900097: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-03 11:52:36.900739: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-03 11:52:36.900761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1594] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-05-03 11:52:36.901175: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-03 11:52:36.901220: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3443 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "INFO:tensorflow:Reading unweighted datasets: ['annotations/valid.record']\n",
      "I0503 11:52:37.134531 139636483225408 dataset_builder.py:162] Reading unweighted datasets: ['annotations/valid.record']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['annotations/valid.record']\n",
      "I0503 11:52:37.135492 139636483225408 dataset_builder.py:79] Reading record datasets for input file: ['annotations/valid.record']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I0503 11:52:37.135578 139636483225408 dataset_builder.py:80] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W0503 11:52:37.135644 139636483225408 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
      "W0503 11:52:37.138246 139636483225408 deprecation.py:345] From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0503 11:52:37.162120 139636483225408 deprecation.py:345] From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W0503 11:52:40.479915 139636483225408 deprecation.py:345] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0503 11:52:41.282824 139636483225408 deprecation.py:345] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Waiting for new checkpoint at models/my_ssd_resnet50_v1_fpn\n",
      "I0503 11:52:43.327079 139636483225408 checkpoint_utils.py:140] Waiting for new checkpoint at models/my_ssd_resnet50_v1_fpn\n",
      "INFO:tensorflow:Found new checkpoint at models/my_ssd_resnet50_v1_fpn/ckpt-3\n",
      "I0503 11:52:43.332813 139636483225408 checkpoint_utils.py:149] Found new checkpoint at models/my_ssd_resnet50_v1_fpn/ckpt-3\n",
      "/usr/local/lib/python3.6/dist-packages/keras/backend.py:401: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-03 11:52:43.449414: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "I0503 11:52:49.078908 139636483225408 api.py:446] feature_map_spatial_dims: [(32, 32), (16, 16), (8, 8), (4, 4), (2, 2)]\n",
      "I0503 11:53:00.154425 139636483225408 api.py:446] feature_map_spatial_dims: [(32, 32), (16, 16), (8, 8), (4, 4), (2, 2)]\n",
      "2023-05-03 11:53:03.521841: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8100\n",
      "2023-05-03 11:53:05.891574: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/eval_util.py:929: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0503 11:53:06.599727 139636483225408 deprecation.py:345] From /usr/local/lib/python3.6/dist-packages/object_detection/eval_util.py:929: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Finished eval step 0\n",
      "I0503 11:53:06.609634 139636483225408 model_lib_v2.py:966] Finished eval step 0\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:464: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "W0503 11:53:06.815575 139636483225408 deprecation.py:345] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:464: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "INFO:tensorflow:Performing evaluation on 7 images.\n",
      "I0503 11:53:07.804555 139636483225408 coco_evaluation.py:293] Performing evaluation on 7 images.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "I0503 11:53:07.806186 139636483225408 coco_tools.py:116] Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "I0503 11:53:07.807024 139636483225408 coco_tools.py:138] DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.12s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.030\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.104\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.030\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.073\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.145\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.145\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "INFO:tensorflow:Eval metrics at step 2000\n",
      "I0503 11:53:07.941321 139636483225408 model_lib_v2.py:1015] Eval metrics at step 2000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.030349\n",
      "I0503 11:53:07.944220 139636483225408 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP: 0.030349\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.104404\n",
      "I0503 11:53:07.945541 139636483225408 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.104404\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.005043\n",
      "I0503 11:53:07.946735 139636483225408 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.005043\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): 0.030373\n",
      "I0503 11:53:07.955666 139636483225408 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (small): 0.030373\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): -1.000000\n",
      "I0503 11:53:07.957355 139636483225408 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (medium): -1.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): -1.000000\n",
      "I0503 11:53:07.958389 139636483225408 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (large): -1.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.005000\n",
      "I0503 11:53:07.959577 139636483225408 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@1: 0.005000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.073333\n",
      "I0503 11:53:07.960830 139636483225408 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@10: 0.073333\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.145000\n",
      "I0503 11:53:07.962793 139636483225408 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100: 0.145000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): 0.145000\n",
      "I0503 11:53:07.964350 139636483225408 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (small): 0.145000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): -1.000000\n",
      "I0503 11:53:07.965838 139636483225408 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (medium): -1.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): -1.000000\n",
      "I0503 11:53:07.967190 139636483225408 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (large): -1.000000\n",
      "INFO:tensorflow:\t+ Loss/localization_loss: 0.784829\n",
      "I0503 11:53:07.968449 139636483225408 model_lib_v2.py:1018] \t+ Loss/localization_loss: 0.784829\n",
      "INFO:tensorflow:\t+ Loss/classification_loss: 0.516141\n",
      "I0503 11:53:07.969506 139636483225408 model_lib_v2.py:1018] \t+ Loss/classification_loss: 0.516141\n",
      "INFO:tensorflow:\t+ Loss/regularization_loss: 2.027389\n",
      "I0503 11:53:07.971997 139636483225408 model_lib_v2.py:1018] \t+ Loss/regularization_loss: 2.027389\n",
      "INFO:tensorflow:\t+ Loss/total_loss: 3.328358\n",
      "I0503 11:53:07.973211 139636483225408 model_lib_v2.py:1018] \t+ Loss/total_loss: 3.328358\n",
      "INFO:tensorflow:Waiting for new checkpoint at models/my_ssd_resnet50_v1_fpn\n",
      "I0503 11:57:43.433352 139636483225408 checkpoint_utils.py:140] Waiting for new checkpoint at models/my_ssd_resnet50_v1_fpn\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"model_main_tf2.py\", line 114, in <module>\n",
      "    tf.compat.v1.app.run()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py\", line 40, in run\n",
      "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 303, in run\n",
      "    _run_main(main, args)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 251, in _run_main\n",
      "    sys.exit(main(argv))\n",
      "  File \"model_main_tf2.py\", line 89, in main\n",
      "    wait_interval=300, timeout=FLAGS.eval_timeout)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/object_detection/model_lib_v2.py\", line 1136, in eval_continuously\n",
      "    checkpoint_dir, timeout=timeout, min_interval_secs=wait_interval):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/checkpoint_utils.py\", line 199, in checkpoints_iterator\n",
      "    checkpoint_dir, checkpoint_path, timeout=timeout)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/checkpoint_utils.py\", line 147, in wait_for_new_checkpoint\n",
      "    time.sleep(seconds_to_sleep)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python model_main_tf2.py --model_dir=models/my_ssd_resnet50_v1_fpn --pipeline_config_path=models/my_ssd_resnet50_v1_fpn/pipeline.config --checkpoint_dir=models/my_ssd_resnet50_v1_fpn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "405b4d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-03 08:18:35.364822: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-03 08:18:35.372096: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-03 08:18:35.372420: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "TensorBoard 2.6.0 at http://0.0.0.0:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# Run tensorboard within a new terminal\n",
    "# !tensorboard --port 6006 --host 0.0.0.0  --logdir 'models/my_ssd_resnet50_v1_fpn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29f39924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annotations\t exporter_main_v2.py  model_main_tf2.py  pre-trained-models\r\n",
      "exported-models  images\t\t      models\t\t walkthrough.ipynb\r\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63abddf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1191d3d1",
   "metadata": {},
   "source": [
    "## Exporting a trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dda562c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-03 12:29:27.026388: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-03 12:29:27.031018: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-03 12:29:27.031303: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-03 12:29:27.039409: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-03 12:29:27.041314: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-03 12:29:27.041860: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-03 12:29:27.042206: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-03 12:29:27.509953: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-03 12:29:27.510202: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-03 12:29:27.510223: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1594] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-05-03 12:29:27.510379: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-03 12:29:27.510431: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3443 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:463: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.map_fn(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
      "W0503 12:29:27.893268 140686670612288 deprecation.py:616] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:463: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.map_fn(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
      "I0503 12:29:32.484538 140686670612288 api.py:446] feature_map_spatial_dims: [(32, 32), (16, 16), (8, 8), (4, 4), (2, 2)]\n",
      "I0503 12:29:41.868796 140686670612288 api.py:446] feature_map_spatial_dims: [(32, 32), (16, 16), (8, 8), (4, 4), (2, 2)]\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7ff330162e10>, because it is not built.\n",
      "W0503 12:29:44.488965 140686670612288 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7ff330162e10>, because it is not built.\n",
      "2023-05-03 12:29:50.334615: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "I0503 12:29:50.974437 140686670612288 api.py:446] feature_map_spatial_dims: [(32, 32), (16, 16), (8, 8), (4, 4), (2, 2)]\n",
      "W0503 12:29:59.960552 140686670612288 save.py:254] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_fn while saving (showing 5 of 520). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: exported-models/my_model/saved_model/assets\n",
      "I0503 12:30:04.081220 140686670612288 builder_impl.py:781] Assets written to: exported-models/my_model/saved_model/assets\n",
      "INFO:tensorflow:Writing pipeline config file to exported-models/my_model/pipeline.config\n",
      "I0503 12:30:04.715533 140686670612288 config_util.py:254] Writing pipeline config file to exported-models/my_model/pipeline.config\n"
     ]
    }
   ],
   "source": [
    "!python exporter_main_v2.py --input_type image_tensor --pipeline_config_path models/my_ssd_resnet50_v1_fpn/pipeline.config --trained_checkpoint_dir models/my_ssd_resnet50_v1_fpn/ --output_directory exported-models/my_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fc4e9b",
   "metadata": {},
   "source": [
    "## Inferencing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e73b9b8",
   "metadata": {},
   "source": [
    "#### Load the test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03a0f052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files and directories in ' images/test/ ' :\n",
      "['18.139572.91050.png', '18.139572.91051.png', '18.139572.91052.png', '18.139572.91053.png', '18.139572.91054.png', '18.139572.91055.png', '18.139572.91056.png', '18.139572.91057.png', '18.139572.91058.png', '18.139572.91059.png', '18.139572.91060.png', '18.139572.91061.png', '18.139572.91062.png', '18.139572.91063.png', '18.139573.91049.png', '18.139573.91050.png', '18.139573.91051.png', '18.139573.91052.png', '18.139573.91053.png', '18.139573.91054.png', '18.139573.91055.png', '18.139573.91056.png', '18.139573.91057.png', '18.139573.91058.png', '18.139573.91059.png', '18.139573.91060.png', '18.139573.91061.png', '18.139573.91062.png', '18.139573.91063.png', '18.139574.91049.png', '18.139574.91050.png', '18.139574.91051.png', '18.139574.91052.png', '18.139574.91053.png', '18.139574.91054.png', '18.139574.91055.png', '18.139574.91056.png', '18.139574.91057.png', '18.139574.91058.png', '18.139574.91059.png', '18.139574.91060.png', '18.139574.91061.png', '18.139574.91062.png', '18.139574.91063.png']\n",
      "Image_Paths ['images/test/18.139572.91050.png', 'images/test/18.139572.91051.png', 'images/test/18.139572.91052.png', 'images/test/18.139572.91053.png', 'images/test/18.139572.91054.png', 'images/test/18.139572.91055.png', 'images/test/18.139572.91056.png', 'images/test/18.139572.91057.png', 'images/test/18.139572.91058.png', 'images/test/18.139572.91059.png', 'images/test/18.139572.91060.png', 'images/test/18.139572.91061.png', 'images/test/18.139572.91062.png', 'images/test/18.139572.91063.png', 'images/test/18.139573.91049.png', 'images/test/18.139573.91050.png', 'images/test/18.139573.91051.png', 'images/test/18.139573.91052.png', 'images/test/18.139573.91053.png', 'images/test/18.139573.91054.png', 'images/test/18.139573.91055.png', 'images/test/18.139573.91056.png', 'images/test/18.139573.91057.png', 'images/test/18.139573.91058.png', 'images/test/18.139573.91059.png', 'images/test/18.139573.91060.png', 'images/test/18.139573.91061.png', 'images/test/18.139573.91062.png', 'images/test/18.139573.91063.png', 'images/test/18.139574.91049.png', 'images/test/18.139574.91050.png', 'images/test/18.139574.91051.png', 'images/test/18.139574.91052.png', 'images/test/18.139574.91053.png', 'images/test/18.139574.91054.png', 'images/test/18.139574.91055.png', 'images/test/18.139574.91056.png', 'images/test/18.139574.91057.png', 'images/test/18.139574.91058.png', 'images/test/18.139574.91059.png', 'images/test/18.139574.91060.png', 'images/test/18.139574.91061.png', 'images/test/18.139574.91062.png', 'images/test/18.139574.91063.png']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging (1)\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "\n",
    "def load_images():\n",
    "#     base_url = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/test_images/'\n",
    "    \n",
    "    # Get the list of all files and directories\n",
    "    path = \"images/test/\"\n",
    "    dir_list = os.listdir(path)\n",
    "    print(\"Files and directories in '\", path, \"' :\")\n",
    "    # prints all files\n",
    "    print(dir_list)\n",
    "    \n",
    "    filenames = dir_list\n",
    "    image_paths = []\n",
    "    for filename in filenames:\n",
    "#         image_path = tf.keras.utils.get_file(fname=filename,\n",
    "#                                             origin=path + filename,\n",
    "#                                             untar=False)\n",
    "        image_path = pathlib.Path(path+filename)\n",
    "        image_paths.append(str(image_path))\n",
    "    return image_paths\n",
    "\n",
    "IMAGE_PATHS = load_images()\n",
    "print(\"Image_Paths\", IMAGE_PATHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9624c936",
   "metadata": {},
   "source": [
    "#### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbcc4ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...Done! Took 16.5042462348938 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "\n",
    "PATH_TO_MODEL_DIR = \"exported-models/my_model\"\n",
    "PATH_TO_SAVED_MODEL = PATH_TO_MODEL_DIR + \"/saved_model\"\n",
    "\n",
    "print('Loading model...', end='')\n",
    "start_time = time.time()\n",
    "\n",
    "# Load saved model and build the detection function\n",
    "detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print('Done! Took {} seconds'.format(elapsed_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa327e1",
   "metadata": {},
   "source": [
    "#### Load label map data (for plotting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfb296bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_LABELS=\"annotations/label_map.pbtxt\"\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n",
    "                                                                    use_display_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9f1644",
   "metadata": {},
   "source": [
    "#### Putting everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3577ec73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference for images/test/18.139572.91050.png... image path images/test/18.139572.91050.png images/prediction/18.139572.91050.png\n",
      "boxes [[1.73753813e-01 1.85210645e-01 3.55317831e-01 5.12954772e-01]\n",
      " [6.56852245e-01 6.55136287e-01 7.87904859e-01 7.96445072e-01]\n",
      " [1.43333077e-01 5.70587039e-01 2.77028710e-01 7.30959296e-01]\n",
      " [5.77997625e-01 2.82532245e-01 7.32589900e-01 4.05312985e-01]\n",
      " [8.91774118e-01 8.57837498e-04 9.98922765e-01 1.29232764e-01]\n",
      " [4.32483926e-02 9.32795405e-01 2.02625751e-01 9.99510884e-01]\n",
      " [6.93675518e-01 2.62632966e-06 8.44622970e-01 8.46178830e-02]\n",
      " [9.05535281e-01 3.93264860e-01 9.98632610e-01 5.23938596e-01]\n",
      " [7.83690333e-01 3.29815656e-01 9.23049808e-01 4.44277197e-01]\n",
      " [2.77526677e-03 8.12161267e-02 1.89579949e-01 3.49461347e-01]\n",
      " [8.70759130e-01 4.86990303e-01 9.87232089e-01 6.23050511e-01]\n",
      " [5.90804994e-01 5.84146678e-01 6.91590488e-01 6.80894673e-01]\n",
      " [5.31742752e-01 9.36103761e-01 6.67369306e-01 9.99860585e-01]\n",
      " [8.84130716e-01 8.18789363e-01 9.78592038e-01 9.01206613e-01]\n",
      " [1.94143847e-01 7.15832293e-01 2.78833151e-01 8.01006734e-01]\n",
      " [5.31574905e-01 4.67917025e-01 6.34016931e-01 5.37815988e-01]\n",
      " [6.26830697e-01 4.08957273e-01 7.15058088e-01 5.01445413e-01]\n",
      " [9.42892611e-01 6.23946607e-01 9.99723732e-01 7.56657064e-01]\n",
      " [8.12201142e-01 3.38186920e-01 9.74599600e-01 4.55751359e-01]\n",
      " [5.98331571e-01 4.93690491e-01 6.96050882e-01 6.09231949e-01]\n",
      " [9.78304982e-01 7.93841898e-01 9.98837113e-01 9.32493269e-01]\n",
      " [9.83448684e-01 2.02868134e-04 9.97910082e-01 1.23521209e-01]\n",
      " [9.84720707e-01 7.88511097e-01 1.00000000e+00 8.81307542e-01]\n",
      " [9.47584331e-01 8.15559328e-01 9.88173664e-01 9.09543931e-01]\n",
      " [3.04146670e-05 6.85000718e-01 5.93281025e-03 8.01505148e-01]\n",
      " [4.33740728e-02 7.07763672e-01 1.07154220e-01 7.55492806e-01]\n",
      " [9.58670318e-01 5.47999084e-01 1.00000000e+00 6.86202466e-01]\n",
      " [9.88053143e-01 9.26369548e-01 9.95943248e-01 9.80890274e-01]\n",
      " [9.81061399e-01 8.88483286e-01 9.95979607e-01 9.71680641e-01]\n",
      " [9.86822784e-01 9.45955634e-01 9.96483028e-01 9.92377996e-01]\n",
      " [1.75988510e-01 0.00000000e+00 3.51600826e-01 3.65446159e-03]\n",
      " [9.72903430e-01 8.43008339e-01 9.95655835e-01 9.19179738e-01]\n",
      " [4.42506850e-01 9.80716527e-01 5.16762555e-01 9.91172373e-01]\n",
      " [6.67987823e-01 0.00000000e+00 7.24254727e-01 2.10211873e-02]\n",
      " [1.62195973e-03 1.91839382e-01 3.62914354e-02 3.15325856e-01]\n",
      " [6.18943632e-01 4.37840551e-01 7.15055525e-01 5.16768873e-01]\n",
      " [9.54903364e-01 8.13780367e-01 9.97255683e-01 9.22194541e-01]\n",
      " [6.61631465e-01 3.80899711e-03 7.09248543e-01 1.54736582e-02]\n",
      " [7.89091885e-02 6.49288118e-01 1.20844781e-01 6.97653115e-01]\n",
      " [4.20049340e-01 9.75847483e-01 4.86984044e-01 9.91977930e-01]\n",
      " [7.04946741e-02 6.79519892e-01 1.16293676e-01 7.21993566e-01]\n",
      " [9.56845105e-01 8.46177757e-01 9.92488444e-01 9.55529511e-01]\n",
      " [9.78347957e-01 7.95684159e-01 9.96255696e-01 8.58405411e-01]\n",
      " [4.81095493e-01 9.90158856e-01 5.60769737e-01 9.94453013e-01]\n",
      " [4.20489371e-01 9.79869545e-01 4.99772668e-01 9.95868504e-01]\n",
      " [5.23622870e-01 5.75618148e-01 5.85515738e-01 6.34819031e-01]\n",
      " [9.52942908e-01 5.83624780e-01 1.00000000e+00 7.27584898e-01]\n",
      " [5.49247563e-01 0.00000000e+00 6.49721444e-01 9.50507913e-03]\n",
      " [9.95762944e-01 7.62634218e-01 1.00000000e+00 8.25574696e-01]\n",
      " [7.56741036e-03 9.80744660e-01 1.51195889e-02 9.90242302e-01]\n",
      " [8.93468142e-01 3.50406468e-01 9.92765665e-01 4.51869190e-01]\n",
      " [9.86154616e-01 7.67368197e-01 9.95372713e-01 8.47478032e-01]\n",
      " [0.00000000e+00 7.04615533e-01 3.58902430e-03 8.17843378e-01]\n",
      " [9.65171754e-01 9.32338834e-01 9.86083686e-01 9.74947572e-01]\n",
      " [6.73496723e-01 5.06045623e-03 7.28127837e-01 1.67866796e-02]\n",
      " [9.90808249e-01 7.38873541e-01 9.96958137e-01 8.18504035e-01]\n",
      " [5.53628743e-01 6.62378907e-01 6.38361752e-01 7.44435906e-01]\n",
      " [6.83643103e-01 1.46704018e-02 1.00000000e+00 3.15955341e-01]\n",
      " [3.13838460e-02 7.42951572e-01 1.13223523e-01 7.95264661e-01]\n",
      " [6.21739388e-01 0.00000000e+00 6.74641013e-01 7.50100566e-03]\n",
      " [8.33659828e-01 1.67009588e-02 8.92812669e-01 7.29472935e-02]\n",
      " [6.31264508e-01 3.98189962e-01 7.26326287e-01 4.58041131e-01]\n",
      " [6.24958575e-01 5.92146516e-01 7.08074987e-01 6.79579139e-01]\n",
      " [1.21744692e-01 5.59334099e-01 1.84046268e-01 6.38007104e-01]\n",
      " [2.32667997e-01 7.28960514e-01 3.14096093e-01 8.06738734e-01]\n",
      " [7.99341321e-01 9.77913916e-01 8.59071732e-01 9.81453001e-01]\n",
      " [6.69793487e-01 1.08370977e-03 7.50409961e-01 1.32539514e-02]\n",
      " [6.99149609e-01 5.11222333e-03 8.39975238e-01 4.76677865e-02]\n",
      " [7.11305022e-01 0.00000000e+00 9.59085464e-01 1.25776291e-01]\n",
      " [6.20291829e-01 3.14752400e-01 1.00000000e+00 7.54600465e-01]\n",
      " [9.77719069e-01 9.06022847e-01 9.92622256e-01 9.56702769e-01]\n",
      " [6.83462918e-01 2.37999950e-03 7.97088087e-01 2.69612484e-02]\n",
      " [4.32746932e-02 3.19266438e-01 1.54826581e-01 4.08068419e-01]\n",
      " [9.70636666e-01 3.90558451e-01 9.89821255e-01 5.25238633e-01]\n",
      " [6.97841775e-03 6.99297249e-01 2.05207318e-02 7.92339981e-01]\n",
      " [2.10160986e-02 9.66128707e-01 1.78719491e-01 9.96559143e-01]\n",
      " [9.88214135e-01 8.48383307e-01 1.00000000e+00 9.87553954e-01]\n",
      " [9.62215304e-01 7.90380657e-01 9.88315463e-01 8.64762485e-01]\n",
      " [8.55677664e-01 1.13074370e-02 9.12348211e-01 1.03165746e-01]\n",
      " [4.23712358e-02 9.86126423e-01 6.89303651e-02 9.90189195e-01]\n",
      " [8.60908568e-01 1.10886991e-02 9.09925520e-01 7.12575763e-02]\n",
      " [4.40068662e-01 7.82845318e-01 5.91930687e-01 9.29049551e-01]\n",
      " [9.39631090e-03 7.23942876e-01 2.02838015e-02 8.15529943e-01]\n",
      " [4.49890018e-01 9.85764682e-01 5.30231476e-01 9.94178116e-01]\n",
      " [9.86011088e-01 7.53721058e-01 9.92907226e-01 8.07919562e-01]\n",
      " [6.69741869e-01 0.00000000e+00 7.37102032e-01 3.48566212e-02]\n",
      " [4.78401810e-01 5.51284492e-01 5.36513746e-01 6.04264081e-01]\n",
      " [4.01660740e-01 7.94064999e-01 5.60195923e-01 9.50075150e-01]\n",
      " [2.79321551e-01 7.34468102e-01 4.13369000e-01 8.90929580e-01]\n",
      " [8.27297330e-01 8.90594721e-03 9.02793527e-01 9.79677290e-02]\n",
      " [5.25537491e-01 9.94314194e-01 5.56875229e-01 9.98098135e-01]\n",
      " [7.67193437e-01 3.28040957e-01 8.26188803e-01 4.15853262e-01]\n",
      " [4.21579182e-01 7.49497890e-01 5.63092291e-01 8.96491528e-01]\n",
      " [8.31429124e-01 9.88700211e-01 8.91918182e-01 9.91562188e-01]\n",
      " [9.88069475e-01 3.13263535e-02 9.98440444e-01 1.79013342e-01]\n",
      " [7.96927333e-01 0.00000000e+00 8.75712514e-01 5.03956005e-02]\n",
      " [3.04504156e-01 4.82406497e-01 4.29146767e-01 6.09762192e-01]\n",
      " [4.13287252e-01 3.64316523e-01 5.58944702e-01 5.18902659e-01]\n",
      " [8.96736741e-01 4.44561154e-01 9.89610195e-01 5.79103351e-01]\n",
      " [9.92275059e-01 7.66331911e-01 1.00000000e+00 8.82517219e-01]]\n",
      "classes [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "scores [0.9997414  0.99968624 0.99968493 0.9995989  0.98892015 0.9404355\n",
      " 0.92381775 0.91985154 0.86650914 0.8444642  0.81560767 0.80412894\n",
      " 0.5320231  0.5086884  0.41382742 0.39550844 0.38301957 0.38212\n",
      " 0.27767035 0.27602407 0.27560157 0.22734326 0.20191592 0.18476065\n",
      " 0.18248548 0.18007182 0.16996433 0.16328686 0.15278812 0.14199212\n",
      " 0.13767022 0.13339843 0.12718491 0.12717366 0.12629655 0.12401826\n",
      " 0.11938006 0.11467645 0.11105256 0.09910954 0.09534626 0.09364039\n",
      " 0.09326305 0.08959492 0.08654996 0.08558398 0.08545315 0.08287432\n",
      " 0.08265608 0.08040431 0.07985088 0.07949971 0.07627017 0.07542994\n",
      " 0.07404774 0.07358626 0.07253663 0.07142963 0.07035233 0.06737421\n",
      " 0.06625643 0.06593189 0.06491634 0.06363809 0.06248089 0.06157069\n",
      " 0.06109942 0.06050192 0.05862177 0.05758196 0.05638785 0.0550331\n",
      " 0.05482729 0.05368073 0.05360135 0.05353597 0.05305347 0.05233467\n",
      " 0.05215906 0.05104939 0.05101727 0.04996791 0.04861962 0.04834238\n",
      " 0.0480259  0.04762869 0.04760164 0.04703128 0.04686806 0.04658166\n",
      " 0.04644408 0.04579463 0.04498424 0.0443023  0.04410705 0.04404446\n",
      " 0.04352454 0.04318071 0.04312469 0.04272789]\n",
      "number 100\n",
      "image_np_with_detections [[[ 66  70  82]\n",
      "  [ 33  37  49]\n",
      "  [ 23  26  41]\n",
      "  ...\n",
      "  [ 44  51  59]\n",
      "  [ 32  39  47]\n",
      "  [ 25  32  40]]\n",
      "\n",
      " [[ 81  85  94]\n",
      "  [ 54  58  69]\n",
      "  [ 54  58  69]\n",
      "  ...\n",
      "  [ 28  35  43]\n",
      "  [ 25  32  40]\n",
      "  [ 24  31  39]]\n",
      "\n",
      " [[ 81  86  89]\n",
      "  [ 66  71  75]\n",
      "  [ 83  88  92]\n",
      "  ...\n",
      "  [ 22  29  39]\n",
      "  [ 24  31  41]\n",
      "  [ 26  33  43]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[127 255   0]\n",
      "  [127 255   0]\n",
      "  [127 255   0]\n",
      "  ...\n",
      "  [166 168 163]\n",
      "  [172 174 171]\n",
      "  [183 183 183]]\n",
      "\n",
      " [[127 255   0]\n",
      "  [127 255   0]\n",
      "  [127 255   0]\n",
      "  ...\n",
      "  [157 159 154]\n",
      "  [170 172 171]\n",
      "  [182 182 182]]\n",
      "\n",
      " [[127 255   0]\n",
      "  [127 255   0]\n",
      "  [127 255   0]\n",
      "  ...\n",
      "  [154 156 151]\n",
      "  [167 169 168]\n",
      "  [174 176 175]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press Enter to continue...\n",
      "Running inference for images/test/18.139572.91051.png... image path images/test/18.139572.91051.png images/prediction/18.139572.91051.png\n",
      "boxes [[4.74697128e-02 3.89800519e-01 2.28457093e-01 5.61593771e-01]\n",
      " [3.86072844e-01 8.90152812e-01 5.37905693e-01 9.99751091e-01]\n",
      " [2.24637508e-01 0.00000000e+00 4.57236707e-01 2.60202587e-01]\n",
      " [2.09212303e-01 8.37468565e-01 3.48593056e-01 9.99882877e-01]\n",
      " [1.75049543e-01 8.24792027e-01 3.15032691e-01 9.90143061e-01]\n",
      " [2.76764892e-02 8.37340891e-01 1.33202732e-01 9.69267428e-01]\n",
      " [5.98187923e-01 9.94852930e-03 8.58736157e-01 2.41443038e-01]\n",
      " [4.14621830e-01 7.35539943e-02 6.98500872e-01 4.24016416e-01]\n",
      " [8.08324337e-01 1.68454096e-01 9.97128010e-01 4.24971402e-01]\n",
      " [2.80734152e-03 8.21658492e-01 1.00006402e-01 9.49540496e-01]\n",
      " [0.00000000e+00 6.16742253e-01 7.37502351e-02 7.48591900e-01]\n",
      " [1.21758759e-01 8.90450895e-01 1.94302619e-01 9.73249376e-01]\n",
      " [7.01084137e-01 9.81036663e-01 8.40687752e-01 9.98935342e-01]\n",
      " [6.02241606e-04 5.43975413e-01 5.07426448e-02 6.20079815e-01]\n",
      " [8.79011676e-03 8.94531131e-01 9.78760570e-02 9.58831191e-01]\n",
      " [5.09849131e-01 8.15497756e-01 5.98491490e-01 9.05422568e-01]\n",
      " [1.17641464e-02 5.02727181e-03 2.13137031e-01 1.71372831e-01]\n",
      " [3.09661683e-03 9.91866231e-01 2.79122926e-02 1.00000000e+00]\n",
      " [6.75989315e-04 3.32863957e-01 3.23447436e-02 5.11014462e-01]\n",
      " [1.90465022e-02 9.49377596e-01 7.84885362e-02 9.84125435e-01]\n",
      " [8.16440955e-03 5.06297290e-01 6.75732493e-02 5.68781316e-01]\n",
      " [7.51099084e-04 5.05137295e-02 1.41708758e-02 1.82141975e-01]\n",
      " [1.63043104e-02 9.77447331e-01 1.00683957e-01 9.96587336e-01]\n",
      " [2.84084678e-03 7.32667923e-01 3.06320861e-02 7.73733377e-01]\n",
      " [2.32437998e-03 9.92167950e-01 5.57089522e-02 1.00000000e+00]\n",
      " [2.46393494e-03 7.32562244e-01 2.09199768e-02 7.78097332e-01]\n",
      " [3.44849348e-01 9.89315808e-01 3.93163979e-01 9.97927606e-01]\n",
      " [8.93965662e-02 8.68177772e-01 1.67011827e-01 9.60327625e-01]\n",
      " [3.92893143e-03 8.19296837e-01 2.11010650e-02 9.30745721e-01]\n",
      " [5.37775550e-03 7.12465346e-01 3.33608612e-02 7.72312105e-01]\n",
      " [2.25345194e-02 4.20868754e-01 2.38239676e-01 7.27174997e-01]\n",
      " [3.82582277e-01 9.77445185e-01 5.30929029e-01 9.96223867e-01]\n",
      " [0.00000000e+00 5.52510619e-01 5.83936498e-02 6.43636823e-01]\n",
      " [1.12599600e-03 2.06967965e-02 1.26389498e-02 1.57457411e-01]\n",
      " [1.20491628e-03 5.06810844e-03 1.04148807e-02 1.30456269e-01]\n",
      " [0.00000000e+00 9.87511799e-02 9.71573405e-03 1.97740227e-01]\n",
      " [3.13790917e-01 9.86335993e-01 3.81435752e-01 1.00000000e+00]\n",
      " [1.12595968e-03 5.04899204e-01 4.92526218e-02 5.65124929e-01]\n",
      " [1.39151439e-02 4.85261858e-01 7.66708329e-02 5.63266098e-01]\n",
      " [0.00000000e+00 8.19621682e-01 5.97255528e-02 9.26520109e-01]\n",
      " [0.00000000e+00 6.02775097e-01 6.00641966e-02 7.02546954e-01]\n",
      " [4.67135683e-02 9.51643944e-01 1.28469288e-01 9.90600824e-01]\n",
      " [2.43941881e-03 5.17641068e-01 6.07680157e-02 5.83294511e-01]\n",
      " [1.05922341e-01 9.22592342e-01 1.86049044e-01 9.84674752e-01]\n",
      " [5.20917892e-01 7.43759155e-01 6.54918432e-01 8.36426377e-01]\n",
      " [3.59733164e-01 9.83974278e-01 5.01697123e-01 1.00000000e+00]\n",
      " [3.42161298e-01 9.86595094e-01 4.01248336e-01 9.94660199e-01]\n",
      " [2.87022084e-01 9.48633373e-01 3.53075117e-01 9.86433923e-01]\n",
      " [7.11283147e-01 9.76661623e-01 8.16678464e-01 1.00000000e+00]\n",
      " [7.46081024e-02 9.55643713e-01 1.58206388e-01 9.92393076e-01]\n",
      " [7.19339311e-01 9.45549250e-01 8.03855121e-01 9.90260601e-01]\n",
      " [2.38331020e-01 5.74176192e-01 2.81262696e-01 6.48122668e-01]\n",
      " [1.84073478e-01 9.29625690e-01 2.88640738e-01 9.78358567e-01]\n",
      " [2.40537047e-01 5.23873031e-01 2.86449552e-01 5.97230017e-01]\n",
      " [2.10677087e-03 2.67575607e-02 2.15012133e-02 1.42071217e-01]\n",
      " [1.13072917e-01 8.70223701e-01 1.86420754e-01 9.53699648e-01]\n",
      " [5.71679026e-02 9.29965377e-01 1.31888911e-01 9.96330976e-01]\n",
      " [5.33201080e-03 8.86554301e-01 2.62700617e-02 9.34124768e-01]\n",
      " [0.00000000e+00 1.08119614e-01 7.54622510e-03 2.14181513e-01]\n",
      " [3.56956497e-02 8.70491147e-01 1.27054483e-01 9.83993292e-01]\n",
      " [5.41312754e-01 9.83036608e-02 6.25061572e-01 1.88002989e-01]\n",
      " [1.16737083e-01 3.23605258e-04 2.12458715e-01 8.58493894e-03]\n",
      " [3.11919441e-03 8.11011791e-01 1.32859834e-02 8.43889594e-01]\n",
      " [5.76946020e-01 7.43369013e-03 8.00874591e-01 1.95405304e-01]\n",
      " [2.51769960e-01 2.47276038e-01 2.91764855e-01 3.13529521e-01]\n",
      " [3.67930345e-02 9.38210905e-01 1.11254022e-01 9.91019785e-01]\n",
      " [1.38655528e-02 9.85549688e-01 1.21634223e-01 9.97205138e-01]\n",
      " [2.37968445e-01 9.92278934e-01 3.72329891e-01 9.99634743e-01]\n",
      " [7.39649296e-01 5.50944030e-01 7.96881199e-01 6.35624707e-01]\n",
      " [0.00000000e+00 9.25836980e-01 5.04638702e-02 9.65458930e-01]\n",
      " [8.05945158e-01 1.58040449e-01 8.94864202e-01 2.46762142e-01]\n",
      " [0.00000000e+00 9.81153607e-01 8.02759752e-02 9.94190931e-01]\n",
      " [0.00000000e+00 7.47800618e-02 1.30162090e-02 1.46344408e-01]\n",
      " [3.69727731e-01 9.82704878e-01 4.09800768e-01 9.95877266e-01]\n",
      " [1.07184052e-04 6.63892567e-01 6.08866215e-02 7.42813170e-01]\n",
      " [7.41691172e-01 5.78031301e-01 8.03360999e-01 6.59371376e-01]\n",
      " [2.10404862e-02 3.79854083e-01 6.90692291e-02 5.07135332e-01]\n",
      " [1.97683573e-02 1.94667786e-01 1.73846126e-01 3.96688849e-01]\n",
      " [5.86628914e-03 8.04113507e-01 8.17319155e-02 9.21523452e-01]\n",
      " [7.52262771e-04 8.17979693e-01 1.10832863e-02 9.03874755e-01]\n",
      " [7.92342722e-02 9.96464014e-01 1.86563790e-01 1.00000000e+00]\n",
      " [0.00000000e+00 7.37601399e-01 2.56892759e-02 7.84192562e-01]\n",
      " [3.48938555e-01 7.17262030e-01 3.91739756e-01 7.97520876e-01]\n",
      " [7.36163139e-01 6.58101678e-01 8.08070064e-01 7.46787667e-01]\n",
      " [2.70751953e-01 5.51372766e-03 5.53903461e-01 3.07628244e-01]\n",
      " [2.99173174e-04 1.39793485e-01 7.35189486e-03 2.44331658e-01]\n",
      " [1.84249599e-02 4.13826436e-01 8.08709413e-02 5.16265571e-01]\n",
      " [1.13526069e-01 1.23828575e-02 3.23475331e-01 1.82278156e-01]\n",
      " [7.25190401e-01 9.90692854e-01 8.98242712e-01 9.99692321e-01]\n",
      " [5.61024725e-01 9.31694806e-02 6.33295238e-01 1.51847392e-01]\n",
      " [4.38324362e-03 4.64385375e-03 2.35146657e-02 1.13414973e-01]\n",
      " [1.15440056e-01 3.62034619e-01 4.56381202e-01 7.18804538e-01]\n",
      " [2.37254590e-01 0.00000000e+00 4.13245529e-01 3.65919992e-02]\n",
      " [1.79688275e-01 6.75048679e-04 3.55621159e-01 4.43465523e-02]\n",
      " [1.17668463e-03 7.76250362e-01 1.62569135e-02 8.00763845e-01]\n",
      " [7.40567148e-01 1.35259241e-01 8.49850237e-01 2.44806200e-01]\n",
      " [5.88145107e-02 9.90867913e-01 1.65746734e-01 9.98972952e-01]\n",
      " [3.31835121e-01 0.00000000e+00 4.83274907e-01 7.17062056e-02]\n",
      " [1.22634023e-02 4.68186140e-01 6.68461844e-02 5.38868904e-01]\n",
      " [4.10248935e-01 9.83045995e-01 5.52119613e-01 9.98646677e-01]]\n",
      "classes [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "scores [0.99992967 0.99931204 0.99902797 0.99700695 0.9944113  0.9884674\n",
      " 0.984379   0.92885834 0.7829091  0.6109225  0.54378563 0.49652106\n",
      " 0.44051766 0.41163245 0.40246224 0.35260367 0.29239473 0.2856481\n",
      " 0.2783701  0.25094336 0.24837296 0.24787936 0.24620286 0.23289447\n",
      " 0.21057199 0.19314036 0.16079827 0.15850374 0.15818071 0.14728072\n",
      " 0.14566797 0.14174117 0.1396813  0.13924411 0.13628335 0.13590384\n",
      " 0.1309587  0.12420136 0.12146037 0.11451877 0.10743409 0.10657211\n",
      " 0.10554658 0.10409508 0.10127093 0.09749001 0.08762908 0.08530241\n",
      " 0.08463527 0.08159741 0.07902391 0.07812927 0.07628462 0.07493617\n",
      " 0.07414985 0.07302515 0.07239024 0.07030103 0.07018717 0.06861099\n",
      " 0.0680503  0.06714748 0.06544229 0.06363724 0.06221882 0.06082305\n",
      " 0.06046323 0.05948195 0.05876542 0.05828242 0.05699272 0.05646236\n",
      " 0.05353007 0.04899304 0.04850379 0.04768683 0.04678182 0.04609939\n",
      " 0.04559533 0.04477749 0.04426567 0.04258372 0.04182722 0.03961151\n",
      " 0.03945144 0.03934577 0.03926458 0.03843977 0.03810741 0.03774536\n",
      " 0.03774527 0.03666918 0.036629   0.03583184 0.03548692 0.03432005\n",
      " 0.03411357 0.0337966  0.03371028 0.03364692]\n",
      "number 100\n",
      "image_np_with_detections [[[228 228 228]\n",
      "  [227 227 227]\n",
      "  [228 228 228]\n",
      "  ...\n",
      "  [161 165 168]\n",
      "  [159 163 166]\n",
      "  [164 168 171]]\n",
      "\n",
      " [[226 226 226]\n",
      "  [225 225 225]\n",
      "  [227 227 227]\n",
      "  ...\n",
      "  [109 113 114]\n",
      "  [128 132 135]\n",
      "  [156 160 163]]\n",
      "\n",
      " [[228 228 228]\n",
      "  [226 226 226]\n",
      "  [227 227 227]\n",
      "  ...\n",
      "  [ 83  85  84]\n",
      "  [110 112 111]\n",
      "  [134 135 137]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 92  93  77]\n",
      "  [ 93  96  79]\n",
      "  [ 92  95  78]\n",
      "  ...\n",
      "  [ 68  79  75]\n",
      "  [ 56  71  68]\n",
      "  [ 27  43  42]]\n",
      "\n",
      " [[ 92  93  77]\n",
      "  [ 95  96  80]\n",
      "  [ 94  97  80]\n",
      "  ...\n",
      "  [ 58  69  63]\n",
      "  [ 52  67  64]\n",
      "  [ 31  47  44]]\n",
      "\n",
      " [[ 96  97  81]\n",
      "  [ 97  98  82]\n",
      "  [ 94  97  80]\n",
      "  ...\n",
      "  [ 47  58  52]\n",
      "  [ 41  56  51]\n",
      "  [ 45  61  58]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\n",
    "%matplotlib inline\n",
    "\n",
    "def load_image_into_numpy_array(path):\n",
    "    \"\"\"Load an image from file into a numpy array.\n",
    "\n",
    "    Puts image into numpy array to feed into tensorflow graph.\n",
    "    Note that by convention we put it into a numpy array with shape\n",
    "    (height, width, channels), where channels=3 for RGB.\n",
    "\n",
    "    Args:\n",
    "      path: the file path to the image\n",
    "\n",
    "    Returns:\n",
    "      uint8 numpy array with shape (img_height, img_width, 3)\n",
    "    \"\"\"\n",
    "    return np.array(Image.open(path))\n",
    "\n",
    "#for all the prediction bbox without of filter, list of [N, 4]\n",
    "bbox = []\n",
    "# for the corresponding score of shape [N] or None.  If scores=None, then \n",
    "# this function assumes that the boxes to be plotted are groundtruth\n",
    "score = []\n",
    "#for the task_id \n",
    "task_id = []\n",
    "#for the prediction bbox id\n",
    "prediction_id = []\n",
    "\n",
    "output_dir = \"images/prediction/\"\n",
    "if not os.path.exists(output_dir):\n",
    "      os.makedirs(output_dir)\n",
    "\n",
    "for image_path in IMAGE_PATHS:\n",
    "\n",
    "    print('Running inference for {}... '.format(image_path), end='')\n",
    "\n",
    "    image_np = load_image_into_numpy_array(image_path)\n",
    "\n",
    "    # Things to try:\n",
    "    # Flip horizontally\n",
    "    # image_np = np.fliplr(image_np).copy()\n",
    "\n",
    "    # Convert image to grayscale\n",
    "#     image_np = np.tile(\n",
    "#         np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\n",
    "\n",
    "    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
    "    input_tensor = tf.convert_to_tensor(image_np)\n",
    "#     print(\"input_tensor\",input_tensor)\n",
    "    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
    "    input_tensor = input_tensor[tf.newaxis, ...]\n",
    "\n",
    "    # input_tensor = np.expand_dims(image_np, 0)\n",
    "    detections = detect_fn(input_tensor)\n",
    "    \n",
    "    # All outputs are batches tensors.\n",
    "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "    # We're only interested in the first num_detections.\n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                   for key, value in detections.items()}\n",
    "#     print(\"detections\",detections)   \n",
    "    \n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "        \n",
    "    image_np_with_detections = image_np.copy()\n",
    "\n",
    "    vis_image = viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "          image_np_with_detections,\n",
    "          detections['detection_boxes'],\n",
    "          detections['detection_classes'],\n",
    "          detections['detection_scores'],\n",
    "          category_index,\n",
    "          use_normalized_coordinates=True,\n",
    "          max_boxes_to_draw=200,\n",
    "          min_score_thresh=.80,\n",
    "          agnostic_mode=False)\n",
    "    \n",
    "    # image id\n",
    "    task = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    output_path = output_dir + task +\".png\"\n",
    "    \n",
    "    # save prediction image\n",
    "    viz_utils.save_image_array_as_png(vis_image, output_path)\n",
    "    \n",
    "    print(\"image path\", image_path, output_path)\n",
    "    print(\"boxes\", detections['detection_boxes'])\n",
    "    print(\"classes\", detections['detection_classes'])\n",
    "    print(\"scores\", detections['detection_scores'])\n",
    "    print(\"number\", num_detections)\n",
    "    print(\"image_np_with_detections\", image_np_with_detections)\n",
    "    \n",
    "\n",
    "    input(\"Press Enter to continue...\")\n",
    "#     plt.figure()\n",
    "#     plt.imshow(image_np_with_detections)\n",
    "#     print('Done')\n",
    "# plt.show()\n",
    "\n",
    "# sphinx_gallery_thumbnail_number = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0807e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075b744c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b46269",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
